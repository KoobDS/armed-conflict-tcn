{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi -L"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O2k3xvkGISfe",
        "outputId": "a70e91c6-6135-4c9f-be44-39a3a809b7fd"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU 0: NVIDIA A100-SXM4-40GB (UUID: GPU-255851e6-2dbc-a660-f948-720ad34c9c5e)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "import shutil, os, time, json\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "DRIVE = \"/content/drive/MyDrive/ACLED_TCN\"\n",
        "LOCAL = \"/content/local_tcn\"\n",
        "os.makedirs(LOCAL, exist_ok=True)\n",
        "\n",
        "# Big arrays (copy once)\n",
        "for f in [\"X_tcn.npy\", \"y_tcn.npy\", \"sequence_index.csv\"]:\n",
        "    src, dst = f\"{DRIVE}/{f}\", f\"{LOCAL}/{f}\"\n",
        "    if not os.path.exists(dst):\n",
        "        t0 = time.time(); shutil.copy2(src, dst)\n",
        "        print(f\"Copied {f} in {time.time()-t0:.1f}s\")\n",
        "\n",
        "# Code & config (copy every run)\n",
        "for f in [\"train_TCN.py\", \"metrics.py\", \"models\", \"config.yaml\"]:\n",
        "    src = f\"{DRIVE}/{f}\"\n",
        "    dst = f\"{LOCAL}/{os.path.basename(f)}\"\n",
        "    if os.path.isdir(src):\n",
        "        shutil.copytree(src, dst, dirs_exist_ok=True)\n",
        "    else:\n",
        "        shutil.copy2(src, dst)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ZgLAg2IJmw3",
        "outputId": "ecb45588-ed99-4732-ff6f-3052850e3315"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# %cd /content/local_tcn\n",
        "# !python -u train_TCN.py --config config.yaml --eval_only"
      ],
      "metadata": {
        "id": "RAPV0c4WJqKz"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/local_tcn\n",
        "!nohup python -u train_TCN.py --config config.yaml > \"{DRIVE}/train_log.txt\" 2>&1 &\n",
        "print(\"Training launched in background – follow progress:\")\n",
        "!tail -f \"{DRIVE}/train_log.txt\""
      ],
      "metadata": {
        "id": "be4oIba9JvNH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1cbe867e-ae31-4602-dffc-57ceaed7b9b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/local_tcn\n",
            "Training launched in background – follow progress:\n",
            "Training TCN...\n",
            "Epoch 01:   0%|          | 0/3309 [00:00<?, ?it/s]/content/local_tcn/train_TCN.py:39: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at /pytorch/torch/csrc/utils/tensor_numpy.cpp:203.)\n",
            "  torch.from_numpy(self.y[i]).float())\n",
            "/content/local_tcn/train_TCN.py:39: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at /pytorch/torch/csrc/utils/tensor_numpy.cpp:203.)\n",
            "  torch.from_numpy(self.y[i]).float())\n",
            "/content/local_tcn/train_TCN.py:39: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at /pytorch/torch/csrc/utils/tensor_numpy.cpp:203.)\n",
            "  torch.from_numpy(self.y[i]).float())\n",
            "/content/local_tcn/train_TCN.py:39: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at /pytorch/torch/csrc/utils/tensor_numpy.cpp:203.)\n",
            "  torch.from_numpy(self.y[i]).float())\n",
            "Epoch 01 | Train 58.101 | Val 23.002 | LR 1.44e-04 | 1.8 min\n",
            "Epoch 02 | Train 56.933 | Val 23.408 | LR 2.86e-04 | 1.8 min\n",
            "Epoch 03 | Train 54.667 | Val 25.227 | LR 4.29e-04 | 1.8 min\n",
            "Epoch 04 | Train 50.145 | Val 28.492 | LR 5.72e-04 | 1.8 min\n",
            "Epoch 05 | Train 42.126 | Val 26.048 | LR 7.15e-04 | 1.8 min\n",
            "Epoch 06 | Train 32.166 | Val 26.672 | LR 8.57e-04 | 1.8 min\n",
            "Epoch 07 | Train 27.004 | Val 25.458 | LR 1.00e-03 | 1.7 min\n",
            "Epoch 08 | Train 19.800 | Val 25.412 | LR 9.98e-04 | 1.8 min\n",
            "Epoch 09 | Train 16.494 | Val 26.414 | LR 9.93e-04 | 1.8 min\n",
            "Epoch 10 | Train 12.293 | Val 26.302 | LR 9.85e-04 | 1.8 min\n",
            "Epoch 11 | Train 10.728 | Val 26.018 | LR 9.73e-04 | 1.8 min\n",
            "Epoch 12 | Train 9.572 | Val 25.656 | LR 9.58e-04 | 1.8 min\n",
            "Epoch 13 | Train 10.209 | Val 25.684 | LR 9.40e-04 | 1.8 min\n",
            "Epoch 14 | Train 8.981 | Val 25.810 | LR 9.19e-04 | 1.8 min\n",
            "Epoch 15 | Train 8.098 | Val 25.023 | LR 8.95e-04 | 1.8 min\n",
            "Epoch 16 | Train 9.009 | Val 26.401 | LR 8.68e-04 | 1.7 min\n",
            "Epoch 17 | Train 7.195 | Val 26.521 | LR 8.39e-04 | 1.8 min\n",
            "Epoch 18 | Train 6.824 | Val 25.855 | LR 8.07e-04 | 1.8 min\n",
            "Epoch 19 | Train 6.661 | Val 25.916 | LR 7.74e-04 | 1.8 min\n",
            "Epoch 20 | Train 6.196 | Val 26.539 | LR 7.38e-04 | 1.8 min\n",
            "Epoch 21 | Train 5.726 | Val 26.257 | LR 7.01e-04 | 1.8 min\n",
            "Epoch 22 | Train 5.976 | Val 26.297 | LR 6.63e-04 | 1.8 min\n",
            "Epoch 23 | Train 5.501 | Val 25.986 | LR 6.23e-04 | 1.8 min\n",
            "Epoch 24 | Train 5.019 | Val 25.545 | LR 5.83e-04 | 1.7 min\n",
            "Epoch 25 | Train 5.093 | Val 26.492 | LR 5.42e-04 | 1.7 min\n",
            "Epoch 26 | Train 4.924 | Val 26.195 | LR 5.01e-04 | 1.8 min\n",
            "Epoch 27 | Train 4.626 | Val 25.966 | LR 4.59e-04 | 1.7 min\n",
            "Epoch 28 | Train 4.582 | Val 26.271 | LR 4.18e-04 | 1.8 min\n",
            "Epoch 29 | Train 4.732 | Val 26.251 | LR 3.78e-04 | 1.7 min\n",
            "Epoch 30 | Train 4.314 | Val 26.071 | LR 3.38e-04 | 1.8 min\n",
            "Epoch 31 | Train 4.261 | Val 26.047 | LR 3.00e-04 | 1.7 min\n",
            "Epoch 32 | Train 4.082 | Val 26.206 | LR 2.63e-04 | 1.8 min\n",
            "Epoch 33 | Train 3.811 | Val 26.083 | LR 2.27e-04 | 1.7 min\n",
            "Epoch 34 | Train 4.159 | Val 26.079 | LR 1.94e-04 | 1.8 min\n",
            "Epoch 35 | Train 3.719 | Val 26.198 | LR 1.62e-04 | 1.8 min\n",
            "Epoch 36 | Train 3.923 | Val 26.155 | LR 1.33e-04 | 1.8 min\n",
            "Epoch 37 | Train 3.806 | Val 26.065 | LR 1.06e-04 | 1.7 min\n",
            "Epoch 38 | Train 3.655 | Val 25.884 | LR 8.23e-05 | 1.7 min\n",
            "Epoch 39 | Train 3.673 | Val 26.170 | LR 6.12e-05 | 1.8 min\n",
            "Epoch 40 | Train 3.707 | Val 26.113 | LR 4.31e-05 | 1.8 min\n",
            "Epoch 41 | Train 3.586 | Val 26.041 | LR 2.81e-05 | 1.8 min\n",
            "Epoch 42 | Train 3.587 | Val 26.077 | LR 1.63e-05 | 1.8 min\n",
            "Epoch 43 | Train 3.789 | Val 26.056 | LR 7.81e-06 | 1.8 min\n",
            "Epoch 44 | Train 3.586 | Val 26.059 | LR 2.71e-06 | 1.7 min\n",
            "Epoch 45 | Train 3.540 | Val 26.062 | LR 1.00e-06 | 1.8 min\n",
            "Evaluating:   0%|          | 0/3 [00:00<?, ?it/s]/content/local_tcn/train_TCN.py:39: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at /pytorch/torch/csrc/utils/tensor_numpy.cpp:203.)\n",
            "  torch.from_numpy(self.y[i]).float())\n",
            "/content/local_tcn/train_TCN.py:39: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at /pytorch/torch/csrc/utils/tensor_numpy.cpp:203.)\n",
            "  torch.from_numpy(self.y[i]).float())\n",
            "Evaluating: 100%|██████████| 3/3 [00:00<00:00, 11.49it/s]\n",
            "Artifacts saved to /content/drive/MyDrive/ACLED_TCN/outputs/tcn\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "toc_visible": true,
      "provenance": [],
      "gpuType": "A100"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}